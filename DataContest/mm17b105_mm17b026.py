# -*- coding: utf-8 -*-
"""mm17b105_mm17b026.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12jEuxZHHZzvHrdD6BixFrbAEsl29DQWh
"""

# Import Statements

import os
import pandas as pd
import numpy as np
import scipy
import matplotlib.pyplot as plt
import seaborn as sns
import random
import datetime
import warnings
warnings.filterwarnings('ignore')

# Data Loading

bikers = pd.read_csv('../../data/bikers.csv')
tours = pd.read_csv('../../data/tours.csv')
bikers_network = pd.read_csv('../../data/bikers_network.csv')
tour_convoy = pd.read_csv('../../data/tour_convoy.csv')
train = pd.read_csv('../../data/train.csv')
test = pd.read_csv('../../data/test.csv')

tours.rename(columns={'biker_id':'biker_organizer_id'}, inplace=True) # to avoid column name match with biker_id in bikers

# Data Cleaning

bikers['member_since'] = pd.to_datetime(bikers['member_since'].replace("--None",np.nan),format='%d-%m-%Y')
bikers['bornIn'] = pd.to_datetime(bikers['bornIn'].replace(["None", "23-May","16-Mar"],[np.nan,np.nan, np.nan]), format='%Y')
tours['tour_date'] = pd.to_datetime(tours['tour_date'], format='%d-%m-%Y', errors = 'coerce')
train['timestamp'] = pd.to_datetime(train['timestamp'])
test['timestamp'] = pd.to_datetime(test['timestamp'])

# Label Encoding
# Label encoding city, state, pincode, country in tours
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
if tours['city'].isna().sum():
    tours['city'] = encoder.fit_transform(tours['city'].fillna('NaN'))
else:
    tours['city'] = encoder.fit_transform(tours['city'])
encoder = LabelEncoder()
if tours['state'].isna().sum():
    tours['state'] = encoder.fit_transform(tours['state'].fillna('NaN'))
else:
    tours['state'] = encoder.fit_transform(tours['state'])
encoder = LabelEncoder()
if tours['pincode'].isna().sum():
    tours['pincode'] = encoder.fit_transform(tours['pincode'].fillna('NaN'))
else:
    tours['pincode'] = encoder.fit_transform(tours['pincode'])
encoder = LabelEncoder()
if tours['country'].isna().sum():
    tours['country'] = encoder.fit_transform(tours['country'].fillna('NaN'))
else:
    tours['country'] = encoder.fit_transform(tours['country'])

# Label encoding language_id, gender in bikers
encoder = LabelEncoder()
if bikers['language_id'].isna().sum():
    bikers['language_id'] = encoder.fit_transform(bikers['language_id'].fillna('NaN'))
else:
    bikers['language_id'] = encoder.fit_transform(bikers['language_id'])
encoder = LabelEncoder()
if bikers['gender'].isna().sum():
    bikers['gender'] = encoder.fit_transform(bikers['gender'].fillna('NaN'))
else:
    bikers['gender'] = encoder.fit_transform(bikers['gender'])

# Merging train and test data with bikers and tours information

train_new = train.merge(bikers, on='biker_id', how='left')
train_new = train_new.merge(tours, on='tour_id', how='left')
test_new = test.merge(bikers, on='biker_id', how='left')
test_new = test_new.merge(tours, on='tour_id', how='left')

# Cleaning bikers_network and tour_convoy dataframes

bikers_network['friends'] = bikers_network['friends'].apply(lambda x:str(x).split())
tour_convoy.rename(columns={'invited':'invited_bikers'}, inplace=True)
tour_convoy['going'] = tour_convoy['going'].apply(lambda x:str(x).split())
tour_convoy['maybe'] = tour_convoy['maybe'].apply(lambda x:str(x).split())
tour_convoy['invited_bikers'] = tour_convoy['invited_bikers'].apply(lambda x:str(x).split())
tour_convoy['not_going'] = tour_convoy['not_going'].apply(lambda x:str(x).split())

# Merging train and test data with bikers_network and tour_convoy information

train_new = train_new.merge(bikers_network, on='biker_id', how='left')
test_new = test_new.merge(bikers_network, on='biker_id', how='left')
train_new = train_new.merge(tour_convoy, on='tour_id', how='left')
test_new = test_new.merge(tour_convoy, on='tour_id', how='left')

# Creating target with 3 classes (like[1-0], disklike[1-0], NA[0-0])

train_new.loc[train_new[train_new['like']==1].index, 'target'] = "like"
train_new.loc[train_new[train_new['dislike']==1].index, 'target'] = "dislike"
train_new.loc[train_new[(train_new['dislike']==0) & (train_new['like']==0)].index, 'target'] = "NA"

# Label Encoding target

LE_target = LabelEncoder()
train_new['target'] = LE_target.fit_transform(train_new['target'])

# Feature Engineering

# Membership duration for every biker-tour pair (tour_date - member_since)
train_new['membership_duration'] = (train_new['tour_date'] - train_new['member_since']).dt.days
test_new['membership_duration'] = (test_new['tour_date'] - test_new['member_since']).dt.days

# Age on tour date (tour_date - bornIn)
train_new['age_at_tour'] = (train_new['tour_date'].dt.year - train_new['bornIn'].dt.year)
test_new['age_at_tour'] = (test_new['tour_date'].dt.year - test_new['bornIn'].dt.year)

# time_to_prepare for tour = [tour_date - timestamp] : Indicates the prepration time available for the tour
time_to_prepare = (train_new['tour_date'] - train_new['timestamp'])
train_new['time_to_prepare'] = (time_to_prepare.dt.days) + (time_to_prepare.dt.seconds/3600)/24
time_to_prepare_test = (test_new['tour_date'] - test_new['timestamp'])
test_new['time_to_prepare'] = (time_to_prepare_test.dt.days) + (time_to_prepare_test.dt.seconds/3600)/24

# from tour_convoy.csv, we can determine for every biker on how many of his/ her friends are going, interested, invited, not_going, maybe (going) for the tour
train_new['no_of_going'] = train_new['going'].apply(lambda x:len(x))
train_new['no_of_maybe'] = train_new['maybe'].apply(lambda x:len(x))
train_new['no_of_invited_bikers'] = train_new['invited_bikers'].apply(lambda x:len(x))
train_new['no_of_not_going'] = train_new['not_going'].apply(lambda x:len(x))

test_new['no_of_going'] = test_new['going'].apply(lambda x:len(x))
test_new['no_of_maybe'] = test_new['maybe'].apply(lambda x:len(x))
test_new['no_of_invited_bikers'] = test_new['invited_bikers'].apply(lambda x:len(x))
test_new['no_of_not_going'] = test_new['not_going'].apply(lambda x:len(x))

train_new['going_friends'] = train_new.apply(lambda x:len(set(x['friends']).intersection(x['going'])), axis=1)
train_new['maybe_friends'] = train_new.apply(lambda x:len(set(x['friends']).intersection(x['maybe'])), axis=1)
train_new['invited_bikers_friends'] = train_new.apply(lambda x:len(set(x['friends']).intersection(x['invited_bikers'])), axis=1)
train_new['not_going_friends'] = train_new.apply(lambda x:len(set(x['friends']).intersection(x['not_going'])), axis=1)

test_new['going_friends'] = test_new.apply(lambda x:len(set(x['friends']).intersection(x['going'])), axis=1)
test_new['maybe_friends'] = test_new.apply(lambda x:len(set(x['friends']).intersection(x['maybe'])), axis=1)
test_new['invited_bikers_friends'] = test_new.apply(lambda x:len(set(x['friends']).intersection(x['invited_bikers'])), axis=1)
test_new['not_going_friends'] = test_new.apply(lambda x:len(set(x['friends']).intersection(x['not_going'])), axis=1)

# Applying PCA for the tour description features w1-w100

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

Std_Scaler = StandardScaler().fit(train_new.loc[:,'w1':'w100'])

X = Std_Scaler.transform(train_new.loc[:,'w1':'w100'])
X_test = Std_Scaler.transform(test_new.loc[:,'w1':'w100'])

pca = PCA(n_components=3)
pca_fit = pca.fit(X)

X = pca_fit.transform(X)
X_test = pca_fit.transform(X_test)

train_new[['p1','p2','p3']] = pd.DataFrame(X)
test_new[['p1','p2','p3']] = pd.DataFrame(X_test)

train_new.drop(train_new.loc[:,'w1':'w100'],axis=1, inplace=True)
test_new.drop(test_new.loc[:,'w1':'w100'],axis=1, inplace=True)

# Creating new feature tour_id_sub form tour_id
train_new['tour_id_sub'] = train_new['tour_id'].apply(lambda x:x[0:2])
test_new['tour_id_sub'] = test_new['tour_id'].apply(lambda x:x[0:2])

# Label Encoding location_id, area, tour_id, and tour_id_sub together for train_new and test_new

train_new['is_train'] = 1
test_new['is_train'] = 0

merged = pd.concat([train_new,test_new])

LE_loc = LabelEncoder()
merged['location_id'] = LE_loc.fit_transform(merged['location_id'])
LE_area = LabelEncoder()
merged['area'] = LE_area.fit_transform(merged['area'].astype(str))
LE_tour_id = LabelEncoder()
merged['tour_id_encoded'] = LE_tour_id.fit_transform(merged['tour_id'].astype(str))
LE_tour_id_sub = LabelEncoder()
merged['tour_id_sub'] = LE_tour_id_sub.fit_transform(merged['tour_id_sub'].astype(str))

train_new = merged[merged.is_train==1].reset_index(drop=True)
test_new = merged[merged.is_train==0].reset_index(drop=True)

del train_new['is_train']
del test_new['is_train']

#Model Building
t=train_new.drop('target',axis=1)
tt=test_new
train_new_target=train_new['target']
for i in ['biker_id','tour_id','tour_id_encoded','tour_id_sub','target','timestamp',
                    'bornIn', 'like', 'dislike', 'language_id', 'invited','member_since','biker_organizer_id',
                    'tour_date','friends','going', 'maybe', 'invited_bikers', 'not_going']:
  train_new=train_new.drop(i,axis=1)

for i in ['biker_id','tour_id','tour_id_encoded','tour_id_sub','target','timestamp',
                    'bornIn', 'like', 'dislike', 'language_id', 'invited','member_since','biker_organizer_id',
                    'tour_date','friends','going', 'maybe', 'invited_bikers', 'not_going']:
  test_new=test_new.drop(i,axis=1)

# Submission
from lightgbm import LGBMClassifier

model = LGBMClassifier(n_estimators=200,depth=6)
model.fit(train_new,train_new_target)
y_predict_prob = model.predict_proba(test_new)
tt['like_probab'] = y_predict_prob[:,-1]
submission = tt[['biker_id','tour_id','like_probab']].sort_values(by='like_probab',ascending=False)
submission = submission.groupby('biker_id')['tour_id'].apply(lambda x:list(x)).reset_index()
submission['tour_id'] = submission['tour_id'].apply(lambda x:' '.join(x))
submission.to_csv('./mm17b105_mm17b026_'+str(1)+'.csv', index=False)

model = LGBMClassifier(n_estimators=300,depth=10)
model.fit(train_new,train_new_target)
y_predict_prob = model.predict_proba(test_new)
tt['like_probab'] = y_predict_prob[:,-1]
submission = tt[['biker_id','tour_id','like_probab']].sort_values(by='like_probab',ascending=False)
submission = submission.groupby('biker_id')['tour_id'].apply(lambda x:list(x)).reset_index()
submission['tour_id'] = submission['tour_id'].apply(lambda x:' '.join(x))
submission.to_csv('./mm17b105_mm17b026_'+str(2)+'.csv', index=False)

